{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"01_url_preprocessing.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"e9kFNmcKZRzd","colab_type":"text"},"source":["# URL Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"kh0Zr-20IzdW","colab_type":"text"},"source":["We prepare a list of urls which should be accessed during the web crawl. The urls are exctracted from the Alexa top 1 million webites collection. "]},{"cell_type":"markdown","metadata":{"id":"-Q11QWV6ZSH7","colab_type":"text"},"source":["## Data Preparation"]},{"cell_type":"code","metadata":{"id":"BJOd2tpCY9mv","colab_type":"code","colab":{}},"source":["import pandas as pd\n","\n","#import Alexa top 1 million websites from csv file\n","websites_df = pd.read_csv(r\"data\\top-1million-sites_2.csv\", sep = \";\", header = None)\n","\n","#rename columns of data frame\n","websites_df.columns = [\"index\", \"url\"]\n","\n","#print properties of data frame\n","print(websites_df.shape, \"\\n\")\n","print(websites_df.head())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VujWalKzY9nC","colab_type":"code","colab":{}},"source":["#extract observations having an url ending with \".de\" and create a new data frame\n","de_websites_df = websites_df[websites_df.url.str.endswith('.de')]\n","\n","#export data frame containing only \".de\"-website urls to a separate csv file\n","de_websites_df.to_csv(r'data/websites_de.csv', index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dMgf31XfZwxW","colab_type":"text"},"source":["## Import Data Frame with selected URLs"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"PHS6hT0gY9nK","colab_type":"code","outputId":"1d57cfa8-8182-433a-f08f-82e4d3f13450","colab":{}},"source":["import pandas as pd\n","\n","#import data containing \".de\"-websites from csv file and convert to a data frame\n","de_websites_df = pd.read_csv(r\"data/websites_de.csv\", sep = \",\") \n","\n","#print properties of data frame (numer of observations in total, first elements of data frame)\n","print(de_websites_df.shape)\n","print(de_websites_df.head(10))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(23809, 2)\n","   index                    url\n","0     23              google.de\n","1     83              amazon.de\n","2    118                ebay.de\n","3    312  ebay-kleinanzeigen.de\n","4    351                 web.de\n","5    427             spiegel.de\n","6    513            t-online.de\n","7    593                bild.de\n","8    625                chip.de\n","9    691              mobile.de\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1BlCEcidY9nS","colab_type":"text"},"source":["## Filtering Websites"]},{"cell_type":"markdown","metadata":{"id":"2tpXCY_kbc84","colab_type":"text"},"source":["### Remove Domains that are present on Filter Lists"]},{"cell_type":"markdown","metadata":{"id":"t9aN5GFtbldU","colab_type":"text"},"source":["#### Blacklist"]},{"cell_type":"code","metadata":{"id":"RDd6iFYdY9nd","colab_type":"code","colab":{}},"source":["#import os package for folder/file structure functionalities\n","import os\n","#import re package for regular expressions functionalities\n","import re\n","\n","#specify root direction of filter lists\n","root_dir = 'C:/Users/timpe_000/Desktop/IT_Security/fitler_lists/blacklists_ut1'\n","\n","#create a list of all folders (subdirectories) that are in the filter list root directory\n","blacklist_categories = os.listdir(root_dir)\n","\n","#create empty list as container for all domains from the filter lists\n","all_domains = []\n","\n","#loop through all subdirectories in the filter list root directory and access files containing the domains to be indexed\n","for category in blacklist_categories:\n","    #adding \"/domains\" the root path\n","    file_dir = root_dir + '/' + category + '/domains'\n","    \n","    #open file containing the domains\n","    domains = open(file_dir)\n","    \n","    #read file containing domains\n","    domains = domains.readlines()\n","    \n","    #delete all line break operators from the file content\n","    cleaned_list = [re.sub(r'\\n', '', x) for x in domains]\n","    \n","    #add domains to the list of domains\n","    all_domains.append(cleaned_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0F3tz2vzY9nl","colab_type":"code","outputId":"dabe2761-5e68-4ff4-c82a-9e92ae94a96d","colab":{}},"source":["#print first 5 elements of first entry in indexed domains list\n","all_domains[0][:5]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['--little--princess--.tumblr.com',\n"," '-allporn-.tumblr.com',\n"," '-becca-anal-.tumblr.com',\n"," '-celestial-beings-.tumblr.com',\n"," '-cocks.tumblr.com']"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"KO_hLpsKbn5q","colab_type":"text"},"source":["#### Shalla List"]},{"cell_type":"code","metadata":{"id":"GL3R82ZqY9nu","colab_type":"code","colab":{}},"source":["#repeat extraction of indexed lists with filter lists from shallalist\n","root_dir = 'C:/Users/timpe_000/Desktop/IT_Security/fitler_lists/shallalist/BL'\n","\n","shallalist_categories = os.listdir(root_dir)\n","\n","all_domains_shallalist = []\n","\n","for category in shallalist_categories:\n","    file_dir = root_dir + '/' + category + '/domains'\n","\n","    domains = open(file_dir)\n","    domains = domains.readlines()\n","    \n","    cleaned_list = [re.sub(r'\\n', '', x) for x in domains]\n","    \n","    all_domains_shallalist.append(cleaned_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p_sjl1lMY9n0","colab_type":"code","outputId":"7bae94ae-5a0e-4828-888b-bded3b332b8c","colab":{}},"source":["all_domains_shallalist[0][:5]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['000freexxx.com',\n"," '004.frnl.de',\n"," '01sexe.com',\n"," '01viral.com',\n"," '039068a.dialer-select.com']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"100DXRClbs0D","colab_type":"text"},"source":["#### Custom Buzzword List"]},{"cell_type":"code","metadata":{"id":"WV1K729SY9n9","colab_type":"code","colab":{}},"source":["#import custom list with words to be filtered out\n","#open file containing filtering buzzwords\n","custom_list = open(r'C:/Users/timpe_000/Desktop/IT_Security/fitler_lists/blacklist_words.txt')\n","\n","#read file containing filter words\n","custom_list = custom_list.readlines()\n","\n","#remove line break operators\n","custom_list = [re.sub(r'\\n', '', x) for x in custom_list]\n","\n","#remove duplicates in custom list\n","custom_list = list(set(custom_list))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IJs_qIMYbzYI","colab_type":"text"},"source":["### Merge Sublists"]},{"cell_type":"code","metadata":{"id":"C3rHswHmY9oF","colab_type":"code","outputId":"6e1ac65c-1d6c-46af-c427-65d19f513b88","colab":{}},"source":["#turn all lists into single domain list\n","\n","#import package itertools, providing extended list functionalities\n","import itertools\n","\n","#covert list, containing domains in several sublists, into a single list containing all domains from the different filtering categories\n","merged_blacklist = list(itertools.chain(*all_domains))\n","merged_shallalist = list(itertools.chain(*all_domains_shallalist))\n","\n","#print number of domains of the 3 different lists\n","print(len(merged_blacklist))\n","print(len(merged_shallalist))\n","print(len(custom_list))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2474878\n","1285799\n","507\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8HTHpWImb3Qc","colab_type":"text"},"source":["### Keep only URLs with '.de'-Ending in Filter Lists"]},{"cell_type":"code","metadata":{"id":"grCuj7UQY9oL","colab_type":"code","colab":{}},"source":["#to reduce total number of filter elements, only those containing a \".de\"-ending are kept for filtering the list of \".de\"-urls\n","\n","###Blacklist\n","#convert to pandas data frame\n","merged_blacklist = pd.DataFrame(merged_blacklist)\n","\n","#rename column to url\n","merged_blacklist.columns = [\"url\"]\n","\n","#filter .de sites from merged blacklist\n","de_blacklist = merged_blacklist[merged_blacklist.url.str.endswith('.de')]\n","\n","###Shallalist\n","#convert to pandas data frame\n","merged_shallalist = pd.DataFrame(merged_shallalist)\n","\n","#rename column to url\n","merged_shallalist.columns = [\"url\"]\n","\n","#filter .de sites from merged shallalist\n","de_shallalist = merged_shallalist[merged_shallalist.url.str.endswith('.de')]\n","\n","#re-convert data frames to lists\n","de_blacklist = list(de_blacklist['url'])\n","de_shallalist = list(de_shallalist['url'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p8eCVR1JdJb9","colab_type":"text"},"source":["### Filter URLs for Web Crawl"]},{"cell_type":"markdown","metadata":{"id":"-ointzdoeV6L","colab_type":"text"},"source":["#### Indexing Lists"]},{"cell_type":"code","metadata":{"id":"WTesqC4vY9oR","colab_type":"code","colab":{}},"source":["#convert data frame containing \".de\"-urls from alexa top one million websites to a list\n","de_websites_list = list(de_websites_df.url)\n","\n","#remove \".de\"-websites that are contained in one of the filter lists\n","#using set function erases ordering of websites elements\n","filtered_de_websites_list = list(set(de_websites_list) - set(de_blacklist))\n","filtered_de_websites_list = list(set(filtered_de_websites_list) - set(de_shallalist))\n","\n","#extract again .de-urls from unfiltered dataframe to restore original ordering of domains\n","filtered_de_websites_df = de_websites_df[de_websites_df['url'].isin(filtered_de_websites_list)]\n","\n","#convert filtered urls to list\n","filtered_de_websites_list = list(filtered_de_websites_df.url)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tip8GX4dY9oW","colab_type":"code","outputId":"e62dc377-7ead-41d3-feb8-ffbbb499cc9c","colab":{}},"source":["print(de_websites_df.head())\n","print(de_websites_df.shape)\n","print(filtered_de_websites_df.head())\n","print(filtered_de_websites_df.shape)\n","print(filtered_de_websites_list[:10])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["   index                    url\n","0     23              google.de\n","1     83              amazon.de\n","2    118                ebay.de\n","3    312  ebay-kleinanzeigen.de\n","4    351                 web.de\n","(23809, 2)\n","    index                   url\n","14   1349  immobilienscout24.de\n","19   1520               bahn.de\n","20   1570                dhl.de\n","25   1993       deref-web-02.de\n","26   2095            linguee.de\n","(21092, 2)\n","['immobilienscout24.de', 'bahn.de', 'dhl.de', 'deref-web-02.de', 'linguee.de', 'duden.de', 'chefkoch.de', 'check24.de', 'definicion.de', 'mydealz.de']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o0z73dA-eZ8k","colab_type":"text"},"source":["#### Buzzword List"]},{"cell_type":"code","metadata":{"id":"aVZ-QBVjY9oe","colab_type":"code","outputId":"638875cb-ce4a-494d-9a96-47e27e15f9be","colab":{}},"source":["#filter list domains that contain one of the buzzwords as substring, specified in the custom list file\n","for word in custom_list:\n","    filtered_de_websites_list = [x for x in filtered_de_websites_list if word not in x]\n","    \n","#print number of elements after filtering with custom list\n","print(len(filtered_de_websites_list))\n","print(filtered_de_websites_list[0:10])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["20523\n","['immobilienscout24.de', 'bahn.de', 'dhl.de', 'deref-web-02.de', 'linguee.de', 'duden.de', 'chefkoch.de', 'check24.de', 'definicion.de', 'mydealz.de']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LUNv-mAnY9ol","colab_type":"code","colab":{}},"source":["#restore ordering\n","filtered_de_websites_df = filtered_de_websites_df[filtered_de_websites_df['url'].isin(filtered_de_websites_list)]\n","filtered_de_websites_list = list(filtered_de_websites_df.url)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GCbDuX2oY9ow","colab_type":"code","outputId":"6c04ef12-459e-4fee-a782-908a2b59ad91","colab":{}},"source":["print(len(de_websites_list))\n","print(de_websites_list[:10])\n","\n","print(len(filtered_de_websites_list))\n","print(filtered_de_websites_list[:10])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["23809\n","['google.de', 'amazon.de', 'ebay.de', 'ebay-kleinanzeigen.de', 'web.de', 'spiegel.de', 't-online.de', 'bild.de', 'chip.de', 'mobile.de']\n","20523\n","['immobilienscout24.de', 'bahn.de', 'dhl.de', 'deref-web-02.de', 'linguee.de', 'duden.de', 'chefkoch.de', 'check24.de', 'definicion.de', 'mydealz.de']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4qg3F12yghc7","colab_type":"text"},"source":["### Finalize URL-List for Crawling"]},{"cell_type":"code","metadata":{"id":"41-kEO9CY9o2","colab_type":"code","colab":{}},"source":["#adding \"http://\" to all websites\n","filtered_de_websites_list = ['http://' + s for s in filtered_de_websites_list]\n","\n","#export final filtered list containing \".de\"-websites to a csv file\n","filtered_de_websites_df = pd.DataFrame(filtered_de_websites_list)\n","filtered_de_websites_df[0].to_csv(r'data/filtered_websites_de_all.csv', index=False, header=False)"],"execution_count":0,"outputs":[]}]}